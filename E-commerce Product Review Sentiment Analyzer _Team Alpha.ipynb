{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d30ee6-6f22-4b28-85b1-965c62d01879",
   "metadata": {},
   "source": [
    "# E-commerce Product Review Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86adf3b-5fc4-4bc6-8596-4354381cba5a",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The project aims to develop a sentiment analyzer for e-commerce product reviews sourced from Aliexpress, focusing on the Electronics category. The Project involves various aspects of data science, including data acquisition, preprocessing, model development, deployment, and pipeline implementation.\n",
    "\n",
    "### About Company\n",
    "\n",
    "AliExpress is a globally renowned e-commerce platform that connects consumers with millions of products at competitive prices.  AliExpress provides a seamless shopping experience, empowering individuals and businesses to discover, purchase, and sell quality products from trusted sellers across the globe.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "E-commerce platforms grapple with the challenge of analyzing vast amounts of customer feedback to accurately understand product sentiment. Understanding this sentiment is critical for businesses to make informed decisions regarding product improvements, marketing strategies, and customer satisfaction. However, manually analyzing thousands of product reviews is time-consuming and inefficient. Consequently, an automated sentiment analysis solution is required to effectively process and interpret these reviews.\n",
    "\n",
    "### Problem Objectives\n",
    "\n",
    "- Develop an accurate and efficient sentiment analysis model for e-commerce product reviews.\n",
    "\n",
    "- Extract valuable insights from customer reviews to inform product improvement and marketing strategies.\n",
    "\n",
    "- Enhance customer satisfaction by providing businesses with a deeper understanding of customer sentiment.\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This project aimed to develop a sentiment analysis model to understand customer feedback on e-commerce products. We focused on classifying reviews into positive, and negative sentiment.\n",
    "\n",
    "`1. Data Acquisition`\n",
    "\n",
    "We obtained text reviews and star ratings from a database, comprising more than 10,000 rows.\n",
    "\n",
    "`2. Model Development/Deployment`\n",
    "\n",
    "We trained multiple machine learning model to accurately predict the sentiment expressed in reviews.\n",
    "\n",
    "`3. Insights`\n",
    "\n",
    "We analyzed the model's predictions to identify trends and patterns in customer sentiment.\n",
    "\n",
    "### Sentiment Analysis Methodology\n",
    "\n",
    "- Our methodology involved several key steps, including data collection, preprocessing, feature engineering, model training, and evaluation.\n",
    "\n",
    "  1. Data Acquisition\n",
    "  2. Data Preprocessing\n",
    "  3. Feature Engineering\n",
    "  4. Model Development/Training\n",
    "  5. Model Evaluation\n",
    "  6. Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eaf9c6-cc5a-4935-b4c3-92380da2493a",
   "metadata": {},
   "source": [
    "### Team Apha\n",
    "\n",
    "- This presentation explores the application of sentiment analysis to e-commerce product reviews, revealing valuable insights for businesses.\n",
    "\n",
    "### Team Members\n",
    "    1. Ifechukwu Akaeze\n",
    "\n",
    "    2. Daniel Edet Onofiok\n",
    "\n",
    "    3. Okediran Tope Emmanuel\n",
    "\n",
    "    4. Dr. Ezeuchu Emmanuel Uzond\n",
    "\n",
    "    5. Modinat Gbemisola Adesope\n",
    "\n",
    "    6. Adebayo Olalekan\n",
    "\n",
    "    7. Khadijat Oludolapo Adebiyi\n",
    "\n",
    "    8. Chinua Mbajekwe\n",
    "\n",
    "    9. Chinwe Njoku\n",
    "\n",
    "    10. Vincent C. Ajaegbu\n",
    "\n",
    "    11. Ayodele Kehinde Richard\n",
    "\n",
    "    12. Precious Odinakachi Loveday\n",
    "\n",
    "    13. Ifeoluwa Adeniyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50e635-3918-400e-8c78-d40148b0b08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a1471-1557-4df1-a58f-22172a41883e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb1728c9-30e0-4c5f-8919-64aa9b3e3536",
   "metadata": {},
   "source": [
    "# 1. Data Acquisition\n",
    " - Import relevant library (pandas)\n",
    " - Load Dataset\n",
    " - Extract the text reviews (Feedback_translated) and rating columns from the Dataset and Create a new DataFrame\n",
    " - Save the new DataFrame to a CSV file for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62461b9e-82cc-4ad1-99bc-3474ac27f658",
   "metadata": {},
   "source": [
    "`Import library`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62482b40-f2e8-4b0c-922a-32b6315e8065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb1c3d-5d2e-4b0e-bb56-2327b28193ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f7fe710-102c-4597-a132-7609e3cc1af1",
   "metadata": {},
   "source": [
    "`Load dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020b328a-6522-48da-a079-a87192fabea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecomm_data = pd.read_csv('Team Alpha dataset - Team Alpha dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d503921-6d93-448f-a77a-0a5e5189a395",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Feedback_translated</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Downvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005010000000000</td>\n",
       "      <td>100</td>\n",
       "      <td>18-May-24</td>\n",
       "      <td>Very good packaging well protected but not yet...</td>\n",
       "      <td>trÃ¨s bon emballage bien protÃ©gÃ© mais pas en...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a***r</td>\n",
       "      <td>FR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005010000000000</td>\n",
       "      <td>60</td>\n",
       "      <td>29-May-24</td>\n",
       "      <td>lights are extremely bright, we used 1.2v batt...</td>\n",
       "      <td>lights are extremely bright, we used 1.2v batt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon Shopper</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005010000000000</td>\n",
       "      <td>100</td>\n",
       "      <td>25-May-24</td>\n",
       "      <td>I like it very much for my son. It is as the d...</td>\n",
       "      <td>Me gusto mucho para mi hijo. Es tal cual la de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R***S</td>\n",
       "      <td>CL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005010000000000</td>\n",
       "      <td>100</td>\n",
       "      <td>23-Apr-24</td>\n",
       "      <td>corresponds to the description, fast delivery,...</td>\n",
       "      <td>corresponds to the description, fast delivery,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon Shopper</td>\n",
       "      <td>UA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005010000000000</td>\n",
       "      <td>100</td>\n",
       "      <td>3-May-24</td>\n",
       "      <td>As described. Good quality. Batteries not incl...</td>\n",
       "      <td>As described. Good quality. Batteries not incl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J***h</td>\n",
       "      <td>HU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          productId  Rating       Date  \\\n",
       "0  1005010000000000     100  18-May-24   \n",
       "1  1005010000000000      60  29-May-24   \n",
       "2  1005010000000000     100  25-May-24   \n",
       "3  1005010000000000     100  23-Apr-24   \n",
       "4  1005010000000000     100   3-May-24   \n",
       "\n",
       "                                 Feedback_translated  \\\n",
       "0  Very good packaging well protected but not yet...   \n",
       "1  lights are extremely bright, we used 1.2v batt...   \n",
       "2  I like it very much for my son. It is as the d...   \n",
       "3  corresponds to the description, fast delivery,...   \n",
       "4  As described. Good quality. Batteries not incl...   \n",
       "\n",
       "                                            Feedback  Unnamed: 5  \\\n",
       "0  trÃ¨s bon emballage bien protÃ©gÃ© mais pas en...         NaN   \n",
       "1  lights are extremely bright, we used 1.2v batt...         NaN   \n",
       "2  Me gusto mucho para mi hijo. Es tal cual la de...         NaN   \n",
       "3  corresponds to the description, fast delivery,...         NaN   \n",
       "4  As described. Good quality. Batteries not incl...         NaN   \n",
       "\n",
       "             Name Country  Upvotes  Downvotes  \n",
       "0           a***r      FR        0          0  \n",
       "1  Amazon Shopper      US        0          0  \n",
       "2           R***S      CL        0          0  \n",
       "3  Amazon Shopper      UA        0          0  \n",
       "4           J***h      HU        0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecomm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317d685a-4f06-4ee6-ac78-bd2648d065a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2192 entries, 0 to 2191\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   productId            2192 non-null   int64  \n",
      " 1   Rating               2192 non-null   int64  \n",
      " 2   Date                 2192 non-null   object \n",
      " 3   Feedback_translated  1306 non-null   object \n",
      " 4   Feedback             1306 non-null   object \n",
      " 5   Unnamed: 5           0 non-null      float64\n",
      " 6   Name                 2192 non-null   object \n",
      " 7   Country              2190 non-null   object \n",
      " 8   Upvotes              2192 non-null   int64  \n",
      " 9   Downvotes            2192 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(5)\n",
      "memory usage: 171.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check for columns data count, null count, data types\n",
    "ecomm_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e93f20f-a415-4c9e-b8ec-5ac517a5fcf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop duplicate and irrelevant columns - 'feedback' column translated to english as feedback translated, 'Unamed: 5' column - with all entry as nan, hence its irrelevance\n",
    "# ecomm_data = ecomm_data.drop(['Feedback', 'Unnamed: 5'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ec3f2-c90f-4d70-8e62-ae11c656edcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44625531-a5a2-4cf7-bb89-313060a24a74",
   "metadata": {},
   "source": [
    "`Extract the Feedback_translated and rating columns from the Dataset and Create a Nee DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b16a97e-54c5-486d-af56-7f7db26651b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_ecomm_data = ecomm_data[['Feedback_translated', 'Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e7acb6e-38de-4752-85d6-b31e1e26417d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback_translated</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very good packaging well protected but not yet...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lights are extremely bright, we used 1.2v batt...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like it very much for my son. It is as the d...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corresponds to the description, fast delivery,...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As described. Good quality. Batteries not incl...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>looks fine, not tried yet!.......................</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Feedback_translated  Rating\n",
       "0     Very good packaging well protected but not yet...     100\n",
       "1     lights are extremely bright, we used 1.2v batt...      60\n",
       "2     I like it very much for my son. It is as the d...     100\n",
       "3     corresponds to the description, fast delivery,...     100\n",
       "4     As described. Good quality. Batteries not incl...     100\n",
       "...                                                 ...     ...\n",
       "2187                                          Very good     100\n",
       "2188                                                NaN     100\n",
       "2189  looks fine, not tried yet!.......................     100\n",
       "2190                                                NaN     100\n",
       "2191                                                NaN     100\n",
       "\n",
       "[2192 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the new DataFrame\n",
    "extract_ecomm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e2cf1-567b-44b7-8a0c-dc80a97270f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f71add73-648a-4f18-89e1-c7ff7aecf799",
   "metadata": {},
   "source": [
    "`Save the new DataFrame to a CSV file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18cb2121-8fae-4ada-8227-085e72eb575d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save as csv file (file name - 'extracted_reviews.csv')\n",
    "extract_ecomm_data.to_csv('extracted_reviews.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b349a4-fe69-42d5-bbbd-44ea8564e564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85866b-9ed8-46de-8362-f3d9a58598e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4037f700-f5c3-43f7-ab4f-96c1de0ef125",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing\n",
    "- Check/Treat missing data\n",
    "- Create a Sentiment column based on Rating column and Encode using LabelEncoder (to convert Sentiment column into numerical values for model development)\n",
    "- Text Cleaning\n",
    "- Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71f94c-2e61-4b06-a4d4-5104539e802e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3585a16f-906d-4196-9df1-79527c0ceacd",
   "metadata": {},
   "source": [
    "`Check/Treat missing data`\n",
    "- Check for count of rows in column with missing values\n",
    "- Display rows where the column has missing values (NaN)\n",
    "- Determine criteria to treat/replace NaN, checking if all the ratings equal 100 or not\n",
    "- Replace NaN with the determined criteria\n",
    "- Apply and confirm replacement of missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73c4bff1-6c81-426d-88a6-bdf99d4a98d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback_translated</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very good packaging well protected but not yet...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lights are extremely bright, we used 1.2v batt...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like it very much for my son. It is as the d...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corresponds to the description, fast delivery,...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As described. Good quality. Batteries not incl...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>looks fine, not tried yet!.......................</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Feedback_translated  Rating\n",
       "0     Very good packaging well protected but not yet...     100\n",
       "1     lights are extremely bright, we used 1.2v batt...      60\n",
       "2     I like it very much for my son. It is as the d...     100\n",
       "3     corresponds to the description, fast delivery,...     100\n",
       "4     As described. Good quality. Batteries not incl...     100\n",
       "...                                                 ...     ...\n",
       "2187                                          Very good     100\n",
       "2188                                                NaN     100\n",
       "2189  looks fine, not tried yet!.......................     100\n",
       "2190                                                NaN     100\n",
       "2191                                                NaN     100\n",
       "\n",
       "[2192 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_ecomm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a452029-8766-4ea9-96e4-a91e5a6640e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback_translated    886\n",
       "Rating                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for count of rows in column with missing values\n",
    "extract_ecomm_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc256d0c-9cf6-42cf-a728-fa39918d4551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback_translated</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>886 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feedback_translated  Rating\n",
       "29                   NaN     100\n",
       "30                   NaN     100\n",
       "31                   NaN     100\n",
       "32                   NaN     100\n",
       "33                   NaN     100\n",
       "...                  ...     ...\n",
       "2185                 NaN     100\n",
       "2186                 NaN     100\n",
       "2188                 NaN     100\n",
       "2190                 NaN     100\n",
       "2191                 NaN     100\n",
       "\n",
       "[886 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display rows where 'feedback_translated' column has missing values (NaN)\n",
    "missing_feedback_translated = extract_ecomm_data[extract_ecomm_data['Feedback_translated'].isnull()]\n",
    "missing_feedback_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab57a444-44e9-4e7a-a52d-03e2f2b43c15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ratings for missing feedback are 100: False\n"
     ]
    }
   ],
   "source": [
    "# Determine criteria to treat/replace NaN \n",
    "# Let's check if all the ratings for the rows where the feedback_translated column is NaN have the value 100 to help determine how to treat the NaN\n",
    "all_missing_ratings_are_100 = missing_feedback_translated['Rating'].eq(100).all()\n",
    "\n",
    "print(f\"All ratings for missing feedback are 100: {all_missing_ratings_are_100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab96d075-4bcc-4317-b38a-f5fcc2ca7ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Given that not all rows in the rating column are equal to 100, we will use\"No Feedback\" to replace the NaN in the feedback_translated column\n",
    "# In order not to make assumptions that might skew the sentiment interpretation and to maintain the integrity and accuracy of the sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e882810-0fa5-4f83-ba45-e70882623b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace NaN in 'feedback_translated' column with \"No Feedback\" using .loc[] to modify the Extracted DataFrame correctly.\n",
    "extract_ecomm_data.loc[:, 'Feedback_translated'] = extract_ecomm_data['Feedback_translated'].fillna('No Feedback')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e2edceb-4909-4f98-bd80-5c8f851353a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback_translated</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very good packaging well protected but not yet...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lights are extremely bright, we used 1.2v batt...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like it very much for my son. It is as the d...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corresponds to the description, fast delivery,...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As described. Good quality. Batteries not incl...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>looks fine, not tried yet!.......................</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Feedback_translated  Rating\n",
       "0     Very good packaging well protected but not yet...     100\n",
       "1     lights are extremely bright, we used 1.2v batt...      60\n",
       "2     I like it very much for my son. It is as the d...     100\n",
       "3     corresponds to the description, fast delivery,...     100\n",
       "4     As described. Good quality. Batteries not incl...     100\n",
       "...                                                 ...     ...\n",
       "2187                                          Very good     100\n",
       "2188                                        No Feedback     100\n",
       "2189  looks fine, not tried yet!.......................     100\n",
       "2190                                        No Feedback     100\n",
       "2191                                        No Feedback     100\n",
       "\n",
       "[2192 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply and confirm replacement of missing value\n",
    "extract_ecomm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0ca7c-6029-4396-a668-84dce16c89fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a49d1fc-e389-43cc-9109-780c1a37f205",
   "metadata": {},
   "source": [
    "`Create a Sentiment column based on Ratings column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cc82f72-1ced-40a6-bab5-d88332bdf89f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Rating: 20\n",
      "Max Rating: 100\n"
     ]
    }
   ],
   "source": [
    "# Get the minimum and maximum ratings\n",
    "min_rating = extract_ecomm_data['Rating'].min()\n",
    "max_rating = extract_ecomm_data['Rating'].max()\n",
    "\n",
    "print(f'Min Rating: {min_rating}')\n",
    "print(f'Max Rating: {max_rating}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d861c02-677d-4bcd-819a-48b03aaa97dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rating Categories:\n",
    "# Positive Sentiment: Ratings from 75 to 100\n",
    "# Negative Sentiment: Ratings from 0 to 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f67cc098-d074-490d-a646-63938e1bc79d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback_translated</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very good packaging well protected but not yet...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lights are extremely bright, we used 1.2v batt...</td>\n",
       "      <td>60</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like it very much for my son. It is as the d...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corresponds to the description, fast delivery,...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As described. Good quality. Batteries not incl...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>looks fine, not tried yet!.......................</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Feedback_translated  Rating Sentiment\n",
       "0     Very good packaging well protected but not yet...     100  Positive\n",
       "1     lights are extremely bright, we used 1.2v batt...      60  Negative\n",
       "2     I like it very much for my son. It is as the d...     100  Positive\n",
       "3     corresponds to the description, fast delivery,...     100  Positive\n",
       "4     As described. Good quality. Batteries not incl...     100  Positive\n",
       "...                                                 ...     ...       ...\n",
       "2187                                          Very good     100  Positive\n",
       "2188                                        No Feedback     100  Positive\n",
       "2189  looks fine, not tried yet!.......................     100  Positive\n",
       "2190                                        No Feedback     100  Positive\n",
       "2191                                        No Feedback     100  Positive\n",
       "\n",
       "[2192 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to categorize ratings into sentiments based on specified ranges\n",
    "def categorize_sentiment(Rating):\n",
    "    if Rating >= 75:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "# Create the 'sentiment' column based on the 'rating' column\n",
    "extract_ecomm_data.loc[:, 'Sentiment'] = extract_ecomm_data['Rating'].apply(categorize_sentiment)\n",
    "\n",
    "# Display the DataFrame with the new 'sentiment' column\n",
    "extract_ecomm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "814aaa01-da78-468f-8c07-4ea6ecb0bb95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment_Encoded\n",
      "1    2040\n",
      "0     152\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback_translated</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very good packaging well protected but not yet...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lights are extremely bright, we used 1.2v batt...</td>\n",
       "      <td>60</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like it very much for my son. It is as the d...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corresponds to the description, fast delivery,...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As described. Good quality. Batteries not incl...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>looks fine, not tried yet!.......................</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Feedback_translated  Rating Sentiment  \\\n",
       "0     Very good packaging well protected but not yet...     100  Positive   \n",
       "1     lights are extremely bright, we used 1.2v batt...      60  Negative   \n",
       "2     I like it very much for my son. It is as the d...     100  Positive   \n",
       "3     corresponds to the description, fast delivery,...     100  Positive   \n",
       "4     As described. Good quality. Batteries not incl...     100  Positive   \n",
       "...                                                 ...     ...       ...   \n",
       "2187                                          Very good     100  Positive   \n",
       "2188                                        No Feedback     100  Positive   \n",
       "2189  looks fine, not tried yet!.......................     100  Positive   \n",
       "2190                                        No Feedback     100  Positive   \n",
       "2191                                        No Feedback     100  Positive   \n",
       "\n",
       "      Sentiment_Encoded  \n",
       "0                     1  \n",
       "1                     0  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "...                 ...  \n",
       "2187                  1  \n",
       "2188                  1  \n",
       "2189                  1  \n",
       "2190                  1  \n",
       "2191                  1  \n",
       "\n",
       "[2192 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode using LabelEncoder (to convert Sentiment column into numerical values for model development)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode Sentiment using labelEncoder (binary encoding for 'Positive'/'Negative')\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Sentiment' column\n",
    "extract_ecomm_data.loc[:, 'Sentiment_Encoded'] = encoder.fit_transform(extract_ecomm_data['Sentiment'])\n",
    "\n",
    "# Check the distribution of sentiments\n",
    "sentiment_distribution = extract_ecomm_data['Sentiment_Encoded'].value_counts()\n",
    "\n",
    "print(sentiment_distribution)\n",
    "\n",
    "# Display the final DataFrame with encoded sentiment\n",
    "extract_ecomm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ee055-f328-43ad-bb70-ea72c868bbc7",
   "metadata": {},
   "source": [
    "*The Sentiment Distribution indicates that most customer feedback is positive, with 2040 positive sentiments compared to only 152 negative sentiments. This suggests high customer satisfaction with the products, while also highlighting a minimal level of negative sentiment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa3aaa-47dc-4c5a-a920-45837360c1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4669163-562a-4918-a6c1-fdd5c7d32296",
   "metadata": {},
   "source": [
    "`Text Cleaning: *Remove noise, special characters, and irrelevant information*`\n",
    "- Import relevant libraries and download stopwords from NLTK\n",
    "- Define the stop words\n",
    "- Define Function to clean the text\n",
    "- Apply the cleaning function to the 'Feedback_translated' column\n",
    "- View the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d7cd925-2f10-49a9-a524-ff0122dab7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import relevant libraries and download stopwords from NLTK\n",
    "\n",
    "import re                                  # re - Regular Expression, useful for text cleaning (e.g., removing special characters).\n",
    "import nltk                                # nltk - Natural Language Toolkit, a library used for natural language processing tasks like tokenization and stopword removal.\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfa32f56-8fa5-4306-a66c-b33dfd4095a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cff265a9-1b1d-4035-8b03-8fe4d92435ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Function to clean the text\n",
    "def clean_text(text):\n",
    "    # Remove special characters and numbers, keeping only letters and spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)                                              # This regex matches anything that is not a letter or space and replaces it with an empty string\n",
    "    # Convert text to lowercase to ensure uniformity\n",
    "    text = text.lower()                                                                  # This helps in reducing the complexity of the analysis by treating 'Word' and 'word' as the same\n",
    "    # Remove extra spaces between words\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()                                             # This replaces multiple spaces with a single space and trims leading/trailing spaces\n",
    "    # Remove stop words (common words that may not add significant meaning to the text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])           # This creates a list of words, excluding stop words, and joins them back into a string\n",
    "    return text                                                                          # Return the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a87ee075-f951-4a79-aa94-a0236fc08531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the cleaning function to the 'Feedback_translated' column\n",
    "extract_ecomm_data.loc[:, 'Cleaned_Feedback_translated'] = extract_ecomm_data['Feedback_translated'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "810a00b3-19a4-49ee-b753-f64363cbceea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            good packaging well protected yet mounted\n",
       "1    lights extremely bright used v battery instead...\n",
       "2        like much son description put batteries thank\n",
       "3    corresponds description fast delivery well pac...\n",
       "4    described good quality batteries included fast...\n",
       "Name: Cleaned_Feedback_translated, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the cleaned text\n",
    "extract_ecomm_data['Cleaned_Feedback_translated'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1ff94-4e8e-4848-8d9c-1549461c5d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "375524d0-3a72-4083-b1a5-33e31a438950",
   "metadata": {},
   "source": [
    "`Tokenization: *Split text into tokens*`\n",
    "- Import relevant libraries and download punkt from NLTK\n",
    "- Do a sample text to test the tokenization\n",
    "- Perform word tokenization\n",
    "- Tokenize each feedback_translated using NLTK's word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1bcb4ce-9eee-4a41-872f-06b3240dfbd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import relevant libraries and download punkt from NLTK\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')                    # Download the 'punkt' resource, which is necessary for tokenizing text, especially for splitting sentences into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c09a9ac0-6343-4c37-ab8e-76879ab181ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good packaging well protected yet mounted'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do a sample text to test the tokenization - Taking the first feedback as an example\n",
    "sample_text = extract_ecomm_data['Cleaned_Feedback_translated'].iloc[0]\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3998bcd9-dfa7-42d2-96ca-f10019ab2993",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'packaging', 'well', 'protected', 'yet', 'mounted']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform word tokenization\n",
    "tokens = word_tokenize(sample_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3b60829-20a6-4430-9d08-ef5ad09f370c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize each feedback_translated using NLTK's word_tokenize\n",
    "extract_ecomm_data.loc[:, 'Feedback_tokens'] = extract_ecomm_data['Cleaned_Feedback_translated'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9337189a-c921-403f-a1ec-7fa083610f50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback_translated</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Cleaned_Feedback_translated</th>\n",
       "      <th>Feedback_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very good packaging well protected but not yet...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>good packaging well protected yet mounted</td>\n",
       "      <td>[good, packaging, well, protected, yet, mounted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lights are extremely bright, we used 1.2v batt...</td>\n",
       "      <td>60</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>lights extremely bright used v battery instead...</td>\n",
       "      <td>[lights, extremely, bright, used, v, battery, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like it very much for my son. It is as the d...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>like much son description put batteries thank</td>\n",
       "      <td>[like, much, son, description, put, batteries,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corresponds to the description, fast delivery,...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>corresponds description fast delivery well pac...</td>\n",
       "      <td>[corresponds, description, fast, delivery, wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As described. Good quality. Batteries not incl...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>described good quality batteries included fast...</td>\n",
       "      <td>[described, good, quality, batteries, included...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>feedback</td>\n",
       "      <td>[feedback]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>looks fine, not tried yet!.......................</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>looks fine tried yet</td>\n",
       "      <td>[looks, fine, tried, yet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>feedback</td>\n",
       "      <td>[feedback]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>feedback</td>\n",
       "      <td>[feedback]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Feedback_translated  Rating Sentiment  \\\n",
       "0     Very good packaging well protected but not yet...     100  Positive   \n",
       "1     lights are extremely bright, we used 1.2v batt...      60  Negative   \n",
       "2     I like it very much for my son. It is as the d...     100  Positive   \n",
       "3     corresponds to the description, fast delivery,...     100  Positive   \n",
       "4     As described. Good quality. Batteries not incl...     100  Positive   \n",
       "...                                                 ...     ...       ...   \n",
       "2187                                          Very good     100  Positive   \n",
       "2188                                        No Feedback     100  Positive   \n",
       "2189  looks fine, not tried yet!.......................     100  Positive   \n",
       "2190                                        No Feedback     100  Positive   \n",
       "2191                                        No Feedback     100  Positive   \n",
       "\n",
       "      Sentiment_Encoded                        Cleaned_Feedback_translated  \\\n",
       "0                     1          good packaging well protected yet mounted   \n",
       "1                     0  lights extremely bright used v battery instead...   \n",
       "2                     1      like much son description put batteries thank   \n",
       "3                     1  corresponds description fast delivery well pac...   \n",
       "4                     1  described good quality batteries included fast...   \n",
       "...                 ...                                                ...   \n",
       "2187                  1                                               good   \n",
       "2188                  1                                           feedback   \n",
       "2189                  1                               looks fine tried yet   \n",
       "2190                  1                                           feedback   \n",
       "2191                  1                                           feedback   \n",
       "\n",
       "                                        Feedback_tokens  \n",
       "0      [good, packaging, well, protected, yet, mounted]  \n",
       "1     [lights, extremely, bright, used, v, battery, ...  \n",
       "2     [like, much, son, description, put, batteries,...  \n",
       "3     [corresponds, description, fast, delivery, wel...  \n",
       "4     [described, good, quality, batteries, included...  \n",
       "...                                                 ...  \n",
       "2187                                             [good]  \n",
       "2188                                         [feedback]  \n",
       "2189                          [looks, fine, tried, yet]  \n",
       "2190                                         [feedback]  \n",
       "2191                                         [feedback]  \n",
       "\n",
       "[2192 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_ecomm_review = extract_ecomm_data\n",
    "cleaned_ecomm_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f2495-efa0-4b08-977f-8b2713f8fa5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1d9f0-96c0-4fba-be8a-7050d1840ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebd7811e-8b27-4bb3-b32c-c59a8196c469",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering\n",
    "- Bag of Words Vectors (BoW)\n",
    "- TF-IDF - Term Frequency-Inverse Document Frequency\n",
    "- Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905a2c2-73a3-4ce4-bbb0-3b5df2fdcc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4911bc1c-512d-4e4e-b480-600deff461b5",
   "metadata": {},
   "source": [
    "`Bag of Words Vectors (BoW): Convert text into a matrix of token counts using CountVectorizer from sklearn.`\n",
    "- Import the relevant libraries\n",
    "- Initialize the CountVectorizer (BoW)\n",
    "- Apply BoW to the 'Cleaned_Feedback_translated' column\n",
    "- Check the shape of the BoW feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b95635f6-8157-443a-8b7c-98d7bc038b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the relevant libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4dfce2d7-3d89-489d-81d9-2e7e5b8b360d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer (BoW)\n",
    "bow_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c45164b9-8498-42dc-ab61-670738836c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply BoW to the 'Cleaned_Feedback_translated' column\n",
    "bow_matrix = bow_vectorizer.fit_transform(cleaned_ecomm_review['Cleaned_Feedback_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe572ac1-8a48-4cf5-91f3-1b54a7df91e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2192, 2655)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the BoW feature matrix\n",
    "bow_matrix.shape                               # Prints the dimensions of the transformed BoW matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a2fe4-c5df-4b09-b4cc-06bd70fd6700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d32f81ab-5a15-495a-97f4-77c2506cdbbd",
   "metadata": {},
   "source": [
    "`TF-IDF - Term Frequency-Inverse Document Frequency: Use TfidfVectorizer to account for word frequency while downweighting common words that appear in many feedback reviews.`\n",
    "- Import the relevant libraries\n",
    "- Initialize the TfidfVectorizer\n",
    "- Apply TF-IDF to the 'Cleaned_Feedback_translated' column\n",
    "- Check the shape of the TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "505ccd28-24b0-4627-985a-9d6be96bde57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eca717ed-0fc7-447a-8227-9ce68fc9e625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c53aa74-2c4d-4644-a299-13fbda802fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply TF-IDF to the 'Cleaned_Feedback_translated' column\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(cleaned_ecomm_review['Cleaned_Feedback_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b830e547-7c8d-404b-8c84-73ce99c90adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2192, 2655)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the TF-IDF feature matrix\n",
    "tfidf_matrix.shape                                # Prints the dimensions of the TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee090a-d8fe-4c6f-ac21-bc53cb32cae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e3d223-121a-4774-9d9d-a09d0d8493e8",
   "metadata": {},
   "source": [
    "`Data Splitting`\n",
    "- Split the dataset into training and test sets (Train-Test Split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1cf6b41-c069-417b-861c-c340fcb9e7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# BoW Train-Test Split\n",
    "X_train_bow,X_test_bow,y_train,y_test = train_test_split(bow_matrix, cleaned_ecomm_review['Sentiment_Encoded'], \n",
    "                                                                 test_size = 0.2, random_state = 42, stratify = cleaned_ecomm_review['Sentiment_Encoded'])    # x = bow_matrix, y = Sentiment_Encoded (Target column)\n",
    "                                                                                                                                                              # stratify argument to maintain the class balance\n",
    "# TF-IDF Train-Test Split\n",
    "X_train_tfidf,X_test_tfidf,y_train,y_test = train_test_split(tfidf_matrix, cleaned_ecomm_review['Sentiment_Encoded'], \n",
    "                                                                 test_size = 0.2, random_state = 42, stratify = cleaned_ecomm_review['Sentiment_Encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92cf22-ad39-4bab-80d1-1c287008ae09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b55c2d79-115c-422d-bab1-d77066f7f474",
   "metadata": {},
   "source": [
    "# 4. Model Development\n",
    "- Pre-trained VADER model\n",
    "- Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e21485-9885-415b-81df-0d977da12ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0538225-ecaf-407c-8732-834ae54ec92f",
   "metadata": {},
   "source": [
    "`Pre-trained VADER Model` - `VADER: Valence Aware Dictionary and sEntiment Reasoner is a pre-trained sentiment analysis tool designed to analyze text for sentiment polarity and intensity, particularly effective for social media and short texts. It uses a lexicon of sentiment related words and rules to score and classify text as positive, negative, or neutral.`\n",
    "- Import relevant Libraries and download 'vader_lexicon' from NLTK\n",
    "- Initialize the VADER sentiment analyzer\n",
    "- Create a Function to calculate sentiment score using VADER\n",
    "- Apply VADER sentiment analysis to the Cleaned_Feedback_translated column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bab1856-1faa-4720-acff-50498332439f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import relevant Libraries and download 'vader_lexicon' from NLTK\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44f7df01-f9d4-41e7-a4b3-604da37abcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1825b75-eac4-4c13-a5b4-e597966436fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Function to calculate sentiment score using VADER\n",
    "def vader_sentiment(text):\n",
    "    sentiment_score = vader_analyzer.polarity_scores(text)\n",
    "     \n",
    "    # Adjust thresholds for sentiment classification\n",
    "    threshold_positive = 0.01\n",
    "    threshold_negative = -0.01\n",
    "    \n",
    "    # Classify the sentiment as positive or negative based on the compound score\n",
    "    if sentiment_score['compound'] >= threshold_positive:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87f85910-bf90-495d-a817-a71de64f56e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply VADER sentiment analysis to the Cleaned_Feedback_translated column\n",
    "cleaned_ecomm_review.loc[:, 'vader_sentiment'] = cleaned_ecomm_review['Cleaned_Feedback_translated'].apply(vader_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92d98646-1046-4fd8-83e5-cc6f13c42c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback_translated</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Cleaned_Feedback_translated</th>\n",
       "      <th>Feedback_tokens</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very good packaging well protected but not yet...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>good packaging well protected yet mounted</td>\n",
       "      <td>[good, packaging, well, protected, yet, mounted]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lights are extremely bright, we used 1.2v batt...</td>\n",
       "      <td>60</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>lights extremely bright used v battery instead...</td>\n",
       "      <td>[lights, extremely, bright, used, v, battery, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like it very much for my son. It is as the d...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>like much son description put batteries thank</td>\n",
       "      <td>[like, much, son, description, put, batteries,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corresponds to the description, fast delivery,...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>corresponds description fast delivery well pac...</td>\n",
       "      <td>[corresponds, description, fast, delivery, wel...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As described. Good quality. Batteries not incl...</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>described good quality batteries included fast...</td>\n",
       "      <td>[described, good, quality, batteries, included...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Very good</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>[good]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>feedback</td>\n",
       "      <td>[feedback]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>looks fine, not tried yet!.......................</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>looks fine tried yet</td>\n",
       "      <td>[looks, fine, tried, yet]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>feedback</td>\n",
       "      <td>[feedback]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>No Feedback</td>\n",
       "      <td>100</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>feedback</td>\n",
       "      <td>[feedback]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Feedback_translated  Rating Sentiment  \\\n",
       "0     Very good packaging well protected but not yet...     100  Positive   \n",
       "1     lights are extremely bright, we used 1.2v batt...      60  Negative   \n",
       "2     I like it very much for my son. It is as the d...     100  Positive   \n",
       "3     corresponds to the description, fast delivery,...     100  Positive   \n",
       "4     As described. Good quality. Batteries not incl...     100  Positive   \n",
       "...                                                 ...     ...       ...   \n",
       "2187                                          Very good     100  Positive   \n",
       "2188                                        No Feedback     100  Positive   \n",
       "2189  looks fine, not tried yet!.......................     100  Positive   \n",
       "2190                                        No Feedback     100  Positive   \n",
       "2191                                        No Feedback     100  Positive   \n",
       "\n",
       "      Sentiment_Encoded                        Cleaned_Feedback_translated  \\\n",
       "0                     1          good packaging well protected yet mounted   \n",
       "1                     0  lights extremely bright used v battery instead...   \n",
       "2                     1      like much son description put batteries thank   \n",
       "3                     1  corresponds description fast delivery well pac...   \n",
       "4                     1  described good quality batteries included fast...   \n",
       "...                 ...                                                ...   \n",
       "2187                  1                                               good   \n",
       "2188                  1                                           feedback   \n",
       "2189                  1                               looks fine tried yet   \n",
       "2190                  1                                           feedback   \n",
       "2191                  1                                           feedback   \n",
       "\n",
       "                                        Feedback_tokens vader_sentiment  \n",
       "0      [good, packaging, well, protected, yet, mounted]        Positive  \n",
       "1     [lights, extremely, bright, used, v, battery, ...        Positive  \n",
       "2     [like, much, son, description, put, batteries,...        Positive  \n",
       "3     [corresponds, description, fast, delivery, wel...        Positive  \n",
       "4     [described, good, quality, batteries, included...        Positive  \n",
       "...                                                 ...             ...  \n",
       "2187                                             [good]        Positive  \n",
       "2188                                         [feedback]        Negative  \n",
       "2189                          [looks, fine, tried, yet]        Positive  \n",
       "2190                                         [feedback]        Negative  \n",
       "2191                                         [feedback]        Negative  \n",
       "\n",
       "[2192 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_ecomm_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e265443-5c6a-42fc-920e-9a87547765c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91288784-eda9-42eb-aed0-247f206e8f2c",
   "metadata": {},
   "source": [
    "`Custom Models`:\n",
    "`Naive Bayes Model` - preferred for sentiment analysis due to its simplicity, speed, and effectiveness in handling high-dimensional text data, like BoW or TF-IDF features.\n",
    "- Import relevant Libraries\n",
    "- Initialize and Train the Naive Bayes model (BoW and TF-IDF)\n",
    "- Make predictions on the test set (BoW and TF-IDF)\n",
    "- Transform the cleaned feedback translated into numerical feature representations: Bag of Words format using fitted CountVectorizer and TF-IDF format using fitted TfidfVectorizer.\n",
    "- Predict sentiments using the Naive Bayes model for both Bag of Words and TF-IDF features, and update the Cleaned_ecomm_review DataFrame with the new sentiment predictions in 'BoW' and 'TF-IDF' columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78168486-3fd7-4489-9914-216fd9bef018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import relevant Libraries\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "074b6503-525d-4aab-8fc3-6d9af8d82d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize and Train the Naive Bayes model on BoW\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Make predictions on the test set (BoW)\n",
    "y_pred_bow = nb_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "894e302c-8e39-482b-bc00-d3a7b4f08105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize and Train the Naive Bayes model on TF-IDF\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set (TF-IDF)\n",
    "y_pred_tfidf = nb_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa8cb4b0-b04a-498d-8a48-22e4fa65f0e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform the cleaned feedback translated into numerical feature representations: Bag of Words format using fitted CountVectorizer and TF-IDF format using fitted TfidfVectorizer.\n",
    "# bow_test = bow_vectorizer.transform(cleaned_ecomm_review['Cleaned_Feedback_translated'])\n",
    "# tfidf_test = tfidf_vectorizer.transform(cleaned_ecomm_review['Cleaned_Feedback_translated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0726a0-7e30-4714-b443-11194ab11cc7",
   "metadata": {},
   "source": [
    "This code transforms the cleaned feedback translated into numerical feature representations using Bag of Words and TF-IDF formats, enabling the machine learning models to analyze and predict sentiments effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95f4ad0e-1817-4904-a059-27e29d2363c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict sentiments using the Naive Bayes model for both Bag of Words and TF-IDF features, and update the DataFrame with the new sentiment predictions in 'BoW' and 'TF-IDF' columns. \n",
    "# cleaned_ecomm_review.loc[:, 'BoW'] = nb_bow.predict(bow_test)\n",
    "# cleaned_ecomm_review.loc[:, 'TF-IDF'] = nb_tfidf.predict(tfidf_test)\n",
    "# cleaned_ecomm_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8c79b-0846-42e9-8b7d-7765bd2482c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a022e-a357-4755-a315-1ebd1984fa0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2917462-8159-472a-8b61-7f06ba53b389",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation:\n",
    "- Assess model performance using accuracy and F1 score metrics.\n",
    "- Optionally, conduct hyperparameter tuning for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c677406-6456-4f31-8aeb-d37f6ee46783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "143e29f0-ca80-4a89-a078-217cb2968af5",
   "metadata": {},
   "source": [
    "#### Assess model performance using accuracy and F1 score metrics.\n",
    "- Import necessary libraries for evaluation\n",
    "- Evaluate VADER Model Prediction\n",
    "- Evaluate Naive Bayes (BoW) Model\n",
    "- Evaluate Naive Bayes (TF-IDF) Model\n",
    "- Create a DataFrame to consolidate the evaluation metrics (accuracy and F1 score) for the three models: (VADER, Naive Bayes with BoW, and Naive Bayes with TF-IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f2e0db17-8184-4b3d-81af-647ef5cfc8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for evaluation\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbfef3-87e9-4560-9040-f1117414c625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b6060e3-39dd-45b5-8101-ed10c712b225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Vader:\n",
      "VADER Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.08      0.59      0.14       152\n",
      "    Positive       0.94      0.50      0.65      2040\n",
      "\n",
      "    accuracy                           0.50      2192\n",
      "   macro avg       0.51      0.54      0.40      2192\n",
      "weighted avg       0.88      0.50      0.61      2192\n",
      "\n",
      "Evaluation for Naive Bayes (BoW):\n",
      "Classification Report (BoW):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.30      0.38        30\n",
      "           1       0.95      0.98      0.97       409\n",
      "\n",
      "    accuracy                           0.93       439\n",
      "   macro avg       0.74      0.64      0.67       439\n",
      "weighted avg       0.92      0.93      0.93       439\n",
      "\n",
      "Evaluation for Naive Bayes (TF-IDF):\n",
      "Classification Report (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        30\n",
      "           1       0.93      1.00      0.96       409\n",
      "\n",
      "    accuracy                           0.93       439\n",
      "   macro avg       0.47      0.50      0.48       439\n",
      "weighted avg       0.87      0.93      0.90       439\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VADER</td>\n",
       "      <td>50.27%</td>\n",
       "      <td>61.48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes (BoW)</td>\n",
       "      <td>93.39%</td>\n",
       "      <td>92.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes (TF-IDF)</td>\n",
       "      <td>93.17%</td>\n",
       "      <td>89.87%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Accuracy F1 Score\n",
       "0                 VADER   50.27%   61.48%\n",
       "1     Naive Bayes (BoW)   93.39%   92.53%\n",
       "2  Naive Bayes (TF-IDF)   93.17%   89.87%"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate VADER Model Prediction\n",
    "print(\"Evaluation for Vader:\")\n",
    "print(\"VADER Classification Report:\")\n",
    "vader_accuracy = (accuracy_score(cleaned_ecomm_review['Sentiment'], cleaned_ecomm_review['vader_sentiment'])) * 100              # Calculate accuracy - measures how many predictions were correct.\n",
    "vader_f1 = (f1_score(cleaned_ecomm_review['Sentiment'], cleaned_ecomm_review['vader_sentiment'], average='weighted')) * 100      # Calculate F1 score - a weighted average of precision and recall, useful in imbalanced datasets.\n",
    "vader_classification_report = classification_report(cleaned_ecomm_review['Sentiment'], cleaned_ecomm_review['vader_sentiment'])\n",
    "print(vader_classification_report)\n",
    "\n",
    "# Evaluate Naive Bayes (BoW) Model\n",
    "print(\"Evaluation for Naive Bayes (BoW):\")\n",
    "print(\"Classification Report (BoW):\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "bow_accuracy = (accuracy_score(y_test, y_pred_bow)) * 100 \n",
    "bow_f1 = (f1_score(y_test, y_pred_bow, average='weighted')) * 100\n",
    "\n",
    "# Evaluate Naive Bayes (TF-IDF) Model\n",
    "print(\"Evaluation for Naive Bayes (TF-IDF):\")\n",
    "print(\"Classification Report (TF-IDF):\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "tfidf_accuracy = (accuracy_score(y_test, y_pred_tfidf)) * 100  # Calculate accuracy\n",
    "tfidf_f1 = (f1_score(y_test, y_pred_tfidf, average='weighted')) * 100  # Calculate F1 score\n",
    "\n",
    "# Create a DataFrame to consolidate the evaluation metrics (accuracy and F1 score) for the three models: (VADER, Naive Bayes with BoW, and Naive Bayes with TF-IDF).\n",
    "# Create a dictionary with the model names and their corresponding accuracy and F1 scores\n",
    "evaluation_metrics = {\n",
    "    'Model': ['VADER', 'Naive Bayes (BoW)', 'Naive Bayes (TF-IDF)'],\n",
    "    'Accuracy': [vader_accuracy, bow_accuracy, tfidf_accuracy],\n",
    "    'F1 Score': [vader_f1, bow_f1, tfidf_f1]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "evaluation_data = pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "# Define a function to format the numbers as percentages\n",
    "def format_percentage(value):\n",
    "    return f'{value:.2f}%'\n",
    "\n",
    "# Use apply with the custom function for both columns\n",
    "evaluation_data['Accuracy'] = evaluation_data['Accuracy'].apply(format_percentage)\n",
    "evaluation_data['F1 Score'] = evaluation_data['F1 Score'].apply(format_percentage)\n",
    "\n",
    "# print output\n",
    "evaluation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca4dc7-6d4a-421f-9c5a-638d55a5d94c",
   "metadata": {},
   "source": [
    "#### Summary of Model Evaluations\n",
    "`The evaluations of the VADER sentiment analysis model and two Naive Bayes models (Bag of Words and TF-IDF) highlight their performance in predicting Negative and Positive sentiments:`\n",
    "\n",
    "VADER Performance:\n",
    "- Negative: Precision: 8%, Recall: 59%, F1-Score: 14%.\n",
    "- Positive: Precision: 94%, Recall: 50%, F1-Score: 65%.\n",
    "- Overall Accuracy: 50%, Macro F1: 40%, Weighted F1: 62%.\n",
    "- Conclusion: The VADER model demonstrates strong performance in identifying positive sentiments but struggles significantly with accurately classifying negative sentiments.\n",
    "---\n",
    "Naive Bayes (Bag of Words) Performance:\n",
    "- Negative: Precision: 53%, Recall: 30%, F1-Score: 38%.\n",
    "- Positive: Precision: 95%, Recall: 98%, F1-Score: 97%.\n",
    "- Overall Accuracy: 93%, Macro F1: 67%, Weighted F1: 93%.\n",
    "- Conclusion: The Bag of Words approach shows high accuracy driven by strong performance in identifying positive sentiments, although it exhibits weaknesses in detecting negative sentiments.\n",
    "---\n",
    "Naive Bayes (TF-IDF) Performance:\n",
    "- Negative: Precision: 0%, Recall: 0%, F1-Score: 0%.\n",
    "- Positive: Precision: 93%, Recall: 100%, F1-Score: 96%.\n",
    "- Overall Accuracy: 93%, Macro F1: 48%, Weighted F1: 90%.\n",
    "- Conclusion: The TF-IDF model excels in predicting positive sentiments but completely fails to identify negative sentiments, leading to an overall low performance in that regard.\n",
    "---\n",
    "`Given that all models performed well in predicting Positive Sentiment but struggled with predicting Negative Sentiment due to the class imbalance of the data, we will train other models such as:`\n",
    "- Logistics Regression\n",
    "- Xgboost\n",
    "- Optionally, conduct hyperparameter tuning for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bba23-6300-4679-bce8-25248d0aa911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5962c471-f802-48c8-ad42-73f9ec14bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate VADER Model Prediction\n",
    "#print(\"Evaluation for Vader:\")\n",
    "#vader_accuracy = (accuracy_score(cleaned_ecomm_review['Sentiment'], cleaned_ecomm_review['vader_sentiment'])) * 100              # Calculate accuracy\n",
    "#vader_f1 = (f1_score(cleaned_ecomm_review['Sentiment'], cleaned_ecomm_review['vader_sentiment'], average='weighted')) * 100      # Calculate F1 score\n",
    "#vader_classification_report = classification_report(cleaned_ecomm_review['Sentiment'], cleaned_ecomm_review['vader_sentiment'])  \n",
    "\n",
    "#print(\"VADER Classification Report:\")\n",
    "#print(vader_classification_report)\n",
    "#print(f\"VADER Accuracy: {vader_accuracy:.2f}%\")\n",
    "#print(f\"VADER F1 Score: {vader_f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23c7497b-737d-4206-9d53-7c94f8453792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate Naive Bayes (BoW) Model\n",
    "#print(\"Evaluation for Naive Bayes (BoW):\")\n",
    "#bow_accuracy = (accuracy_score(y_test, y_pred_bow)) * 100  # Calculate accuracy\n",
    "#bow_f1 = (f1_score(y_test, y_pred_bow, average='weighted')) * 100  # Calculate F1 score\n",
    "\n",
    "#print(\"Classification Report (BoW):\")\n",
    "#print(classification_report(y_test, y_pred_bow))\n",
    "#print(f\"Accuracy (BoW): {bow_accuracy:.2f}%\")\n",
    "#print(f\"F1 Score (BoW): {bow_f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ad61510-346f-4cc4-9a75-440e72482bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate Naive Bayes (TF-IDF) Model\n",
    "#print(\"Evaluation for Naive Bayes (TF-IDF):\")\n",
    "#tfidf_accuracy = (accuracy_score(y_test, y_pred_tfidf)) * 100  # Calculate accuracy\n",
    "#tfidf_f1 = (f1_score(y_test, y_pred_tfidf, average='weighted')) * 100  # Calculate F1 score\n",
    "\n",
    "#print(\"Classification Report (TF-IDF):\")\n",
    "#print(classification_report(y_test, y_pred_tfidf))\n",
    "#print(f\"Accuracy (TF-IDF): {tfidf_accuracy:.2f}%\")\n",
    "#print(f\"F1 Score (TF-IDF): {tfidf_f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33a89f-55ad-4b2d-b6e9-351535141021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c6e2e-991f-4647-95e0-4390e39d6879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30e0e325-95a9-484b-9083-75d404c93033",
   "metadata": {},
   "source": [
    "#### Logistics Regression Model.\n",
    "- Import necessary libraries\n",
    "- Train the model and make predictions on BoW and TF-IDF\n",
    "#### XGBoost Model.\n",
    "- Import necessary libraries\n",
    "- Train the model and make predictions on BoW and TF-IDF\n",
    "#### Evaluate All Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32d4c4b5-246e-4a40-9ff9-4575a5ce4559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import class_weight\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fe526d9-26c7-43dc-b738-be0f9e36da9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize, Train, and Predict the Logistic Regression model on BoW\n",
    "log_bow = LogisticRegression(class_weight='balanced')                    # Intialize\n",
    "log_bow.fit(X_train_bow, y_train)                                        # Train\n",
    "log_y_pred_bow = log_bow.predict(X_test_bow)                             # Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "94eea95a-5466-4ee6-8a0e-4149616884e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize, Train, and Predict the Logistic Regression model on TF-IDF\n",
    "log_tfidf = LogisticRegression(class_weight='balanced')                  # Initialize\n",
    "log_tfidf.fit(X_train_tfidf, y_train)                                    # Train\n",
    "log_y_pred_tfidf = log_tfidf.predict(X_test_tfidf)                       # Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7091ad1-9493-4152-a5ae-07fdbe4ed978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate scale_pos_weight and Initialize for XGBoost Model\n",
    "positive_count = 409\n",
    "negative_count = 30\n",
    "scale_pos_weight = negative_count / positive_count\n",
    "\n",
    "# Initialize for XGBoost Model\n",
    "xgb_bow = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight)\n",
    "xgb_tfidf = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d75bd5e-9fb1-41a9-b5d1-5458b7619d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and Predict the XGBoost model on BoW\n",
    "xgb_bow.fit(X_train_bow, y_train)                                       # Train\n",
    "xgb_y_pred_bow = xgb_bow.predict(X_test_bow)                            # Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "812e9dc4-33ce-4888-9d97-8c815b6c7a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and Predict the XGBoost model on TF-IDF\n",
    "xgb_tfidf.fit(X_train_tfidf, y_train)                                   # Train\n",
    "xgb_y_pred_tfidf = xgb_tfidf.predict(X_test_tfidf)                      # Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13d4bd6c-2909-4e90-baa7-5fe3685efdd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Vader:\n",
      "VADER Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.08      0.59      0.14       152\n",
      "    Positive       0.94      0.50      0.65      2040\n",
      "\n",
      "    accuracy                           0.50      2192\n",
      "   macro avg       0.51      0.54      0.40      2192\n",
      "weighted avg       0.88      0.50      0.61      2192\n",
      "\n",
      "Evaluation for Naive Bayes (BoW):\n",
      "Classification Report (BoW):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.30      0.38        30\n",
      "           1       0.95      0.98      0.97       409\n",
      "\n",
      "    accuracy                           0.93       439\n",
      "   macro avg       0.74      0.64      0.67       439\n",
      "weighted avg       0.92      0.93      0.93       439\n",
      "\n",
      "Evaluation for Naive Bayes (TF-IDF):\n",
      "Classification Report (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        30\n",
      "           1       0.93      1.00      0.96       409\n",
      "\n",
      "    accuracy                           0.93       439\n",
      "   macro avg       0.47      0.50      0.48       439\n",
      "weighted avg       0.87      0.93      0.90       439\n",
      "\n",
      "Evaluation for Logistic Regression (BoW):\n",
      "Classification Report (BoW):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.50      0.49        30\n",
      "           1       0.96      0.96      0.96       409\n",
      "\n",
      "    accuracy                           0.93       439\n",
      "   macro avg       0.72      0.73      0.73       439\n",
      "weighted avg       0.93      0.93      0.93       439\n",
      "\n",
      "Evaluation for Logistic Regression (TF-IDF):\n",
      "Classification Report (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.67      0.53        30\n",
      "           1       0.97      0.94      0.96       409\n",
      "\n",
      "    accuracy                           0.92       439\n",
      "   macro avg       0.70      0.80      0.74       439\n",
      "weighted avg       0.94      0.92      0.93       439\n",
      "\n",
      "Evaluation for XGBoost (BoW):\n",
      "Classification Report (BoW):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.73      0.36        30\n",
      "           1       0.98      0.83      0.90       409\n",
      "\n",
      "    accuracy                           0.82       439\n",
      "   macro avg       0.61      0.78      0.63       439\n",
      "weighted avg       0.93      0.82      0.86       439\n",
      "\n",
      "Evaluation for XGBoost (TF-IDF):\n",
      "Classification Report (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.73      0.37        30\n",
      "           1       0.98      0.84      0.90       409\n",
      "\n",
      "    accuracy                           0.83       439\n",
      "   macro avg       0.61      0.79      0.64       439\n",
      "weighted avg       0.93      0.83      0.87       439\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VADER</td>\n",
       "      <td>50.27%</td>\n",
       "      <td>61.48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes (BoW)</td>\n",
       "      <td>93.39%</td>\n",
       "      <td>92.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes (TF-IDF)</td>\n",
       "      <td>93.17%</td>\n",
       "      <td>89.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression (BoW)</td>\n",
       "      <td>92.94%</td>\n",
       "      <td>92.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression (TF-IDF)</td>\n",
       "      <td>91.80%</td>\n",
       "      <td>92.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost (BoW)</td>\n",
       "      <td>82.46%</td>\n",
       "      <td>86.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost (TF-IDF)</td>\n",
       "      <td>83.14%</td>\n",
       "      <td>86.64%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model Accuracy F1 Score\n",
       "0                         VADER   50.27%   61.48%\n",
       "1             Naive Bayes (BoW)   93.39%   92.53%\n",
       "2          Naive Bayes (TF-IDF)   93.17%   89.87%\n",
       "3     Logistic Regression (BoW)   92.94%   92.99%\n",
       "4  Logistic Regression (TF-IDF)   91.80%   92.58%\n",
       "5                 XGBoost (BoW)   82.46%   86.17%\n",
       "6              XGBoost (TF-IDF)   83.14%   86.64%"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "# VADER Model Prediction\n",
    "print(\"Evaluation for Vader:\")\n",
    "print(\"VADER Classification Report:\")\n",
    "print(vader_classification_report)\n",
    "vader_accuracy = (accuracy_score(cleaned_ecomm_review['Sentiment'], cleaned_ecomm_review['vader_sentiment'])) * 100             # Calculate accuracy - measures how many predictions were correct.\n",
    "vader_f1 = (f1_score(cleaned_ecomm_review['Sentiment'], cleaned_ecomm_review['vader_sentiment'], average='weighted')) * 100     # Calculate F1 score - a weighted average of precision and recall, useful in imbalanced datasets.\n",
    "vader_classification_report = classification_report(cleaned_ecomm_review['Sentiment'], cleaned_ecomm_review['vader_sentiment'])\n",
    "\n",
    "# Naive Bayes (BoW) Model\n",
    "print(\"Evaluation for Naive Bayes (BoW):\")\n",
    "print(\"Classification Report (BoW):\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "bow_accuracy = (accuracy_score(y_test, y_pred_bow)) * 100 \n",
    "bow_f1 = (f1_score(y_test, y_pred_bow, average='weighted')) * 100\n",
    "\n",
    "# Naive Bayes (TF-IDF) Model\n",
    "print(\"Evaluation for Naive Bayes (TF-IDF):\")\n",
    "print(\"Classification Report (TF-IDF):\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "tfidf_accuracy = (accuracy_score(y_test, y_pred_tfidf)) * 100  # Calculate accuracy\n",
    "tfidf_f1 = (f1_score(y_test, y_pred_tfidf, average='weighted')) * 100  # Calculate F1 score\n",
    "\n",
    "# Logistic Regression (BoW) Model\n",
    "print(\"Evaluation for Logistic Regression (BoW):\")\n",
    "print(\"Classification Report (BoW):\")\n",
    "print(classification_report(y_test, log_y_pred_bow))\n",
    "log_bow_accuracy = (accuracy_score(y_test, log_y_pred_bow)) * 100 \n",
    "log_bow_f1 = (f1_score(y_test, log_y_pred_bow, average='weighted')) * 100\n",
    "\n",
    "# Logistic Regression (TF-IDF) Model\n",
    "print(\"Evaluation for Logistic Regression (TF-IDF):\")\n",
    "print(\"Classification Report (TF-IDF):\")\n",
    "print(classification_report(y_test, log_y_pred_tfidf))\n",
    "log_tfidf_accuracy = (accuracy_score(y_test, log_y_pred_tfidf)) * 100  # Calculate accuracy\n",
    "log_tfidf_f1 = (f1_score(y_test, log_y_pred_tfidf, average='weighted')) * 100  # Calculate F1 score\n",
    "\n",
    "# XGBoost (BoW) Model\n",
    "print(\"Evaluation for XGBoost (BoW):\")\n",
    "print(\"Classification Report (BoW):\")\n",
    "print(classification_report(y_test, xgb_y_pred_bow))\n",
    "xgb_bow_accuracy = (accuracy_score(y_test, xgb_y_pred_bow)) * 100 \n",
    "xgb_bow_f1 = (f1_score(y_test, xgb_y_pred_bow, average='weighted')) * 100\n",
    "\n",
    "# XGBoost (TF-IDF) Model\n",
    "print(\"Evaluation for XGBoost (TF-IDF):\")\n",
    "print(\"Classification Report (TF-IDF):\")\n",
    "print(classification_report(y_test, xgb_y_pred_tfidf))\n",
    "xgb_tfidf_accuracy = (accuracy_score(y_test, xgb_y_pred_tfidf)) * 100  # Calculate accuracy\n",
    "xgb_tfidf_f1 = (f1_score(y_test, xgb_y_pred_tfidf, average='weighted')) * 100  # Calculate F1 score\n",
    "\n",
    "# Create a DataFrame to consolidate the evaluation metrics (accuracy and F1 score) for the three models: (VADER, Naive Bayes with BoW, and Naive Bayes with TF-IDF).\n",
    "# Create a dictionary with the model names and their corresponding accuracy and F1 scores\n",
    "evaluation_metrics1 = {\n",
    "    'Model': ['VADER', 'Naive Bayes (BoW)', 'Naive Bayes (TF-IDF)', 'Logistic Regression (BoW)', 'Logistic Regression (TF-IDF)', 'XGBoost (BoW)', 'XGBoost (TF-IDF)'],\n",
    "    'Accuracy': [vader_accuracy, bow_accuracy, tfidf_accuracy, log_bow_accuracy, log_tfidf_accuracy, xgb_bow_accuracy, xgb_tfidf_accuracy],\n",
    "    'F1 Score': [vader_f1, bow_f1, tfidf_f1, log_bow_f1, log_tfidf_f1, xgb_bow_f1, xgb_tfidf_f1]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "evaluation_data1 = pd.DataFrame(evaluation_metrics1)\n",
    "\n",
    "# Define a function to format the numbers as percentages\n",
    "def format_percentage(value):\n",
    "    return f'{value:.2f}%'\n",
    "\n",
    "# Use apply with the custom function for both columns\n",
    "evaluation_data1['Accuracy'] = evaluation_data1['Accuracy'].apply(format_percentage)\n",
    "evaluation_data1['F1 Score'] = evaluation_data1['F1 Score'].apply(format_percentage)\n",
    "\n",
    "# print output\n",
    "evaluation_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f5a570-f25e-4c85-b10d-74445ad24e5a",
   "metadata": {},
   "source": [
    "#### Summary of All Models Evaluation:\n",
    "1. `VADER` struggles heavily with negative sentiment classification. It has a very low F1-score (14%) for negative sentiment, although it performs decently with positive sentiment (65%). This results in a 50% accuracy, showing it is not reliable for balanced sentiment analysis.\n",
    "\n",
    "2. `Naive Bayes (BoW)` performs well for positive sentiment with an F1-score of 97%, but struggles with negative sentiment detection, reflected in its lower recall (30%) and F1-score (38%) for negatives. Despite this, it achieves a strong overall accuracy of 93%.\n",
    "\n",
    "3. `Naive Bayes (TF-IDF)` has an alarming weakness with negative sentiment detection, with 0% precision, recall, and F1-score for negatives, indicating it cannot identify any negative sentiments. Its strong performance in positive sentiment detection, however, leads to a 93% accuracy.\n",
    "\n",
    "4. `Logistic Regression (BoW)` offers a balanced performance across both sentiment classes. It achieves a respectable F1-score of 49% for negatives and 96% for positives, making it more reliable overall with 93% accuracy. This indicates it is effective for balanced sentiment classification.\n",
    "\n",
    "5. `Logistic Regression (TF-IDF)` shows similar balance to the BoW version, with improved recall for negative sentiment (67%) and still strong positive sentiment detection. It provides a robust 92% accuracy and good F1-scores across the board.\n",
    "\n",
    "6. `XGBoost (BoW)` performs very well for positive sentiment detection (98% precision), but its negative sentiment detection suffers, with only 24% precision and a lower F1-score (36%). This leads to a lower overall accuracy of 82%, making it less reliable for balanced sentiment tasks.\n",
    "\n",
    "7. `XGBoost (TF-IDF)`, like the BoW version, shows strong performance in detecting positive sentiment, but struggles with negatives. Its 37% F1-score for negative sentiment is a slight improvement, but the accuracy of 83% still reflects its imbalance in sentiment classification.\n",
    "\n",
    "`Overall Insight:`\n",
    "Logistic Regression, particularly with the Bag of Words (BoW) and TF-IDF features, offers the most balanced performance for both positive and negative sentiment classification. Naive Bayes shows strength in positive sentiment detection, but is significantly weaker for negative sentiment, while XGBoost models, though effective with positive sentiment, are less capable with negative classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e64ae3-8f0e-4a4a-bbcd-6b637a0579f2",
   "metadata": {},
   "source": [
    "#### Next Steps.\n",
    "1. The need to conduct hyperparameter tuning on logistic regression (BoW/TF-IDF) and xgboost (BoW/TF-IDF).\n",
    "2. Choose the better model after hyperparameter tuning;\n",
    "- logistic regression (BoW) or logistic regression (TF-IDF)\n",
    "- xgboost (BoW) or xgboost (TF-IDF)\n",
    "3. Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0af8b1-f48b-4c70-9430-e7af64a31cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694efbf-7d0c-4053-97e0-4f5f58b17fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ca29b4f-8bd3-434b-8205-1174656f8546",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "To conduct hyperparameter tuning on Logistic Regression (BoW/TF-IDF) and XGBoost (BoW/TF-IDF) models, we'll use GridSearchCV, which helps find the optimal combination of hyperparameters for each model.\n",
    "- Import the relevant libraries\n",
    "---\n",
    "#### Step-by-Step Plan for Hyperparameter Tuning:\n",
    "`Logistic Regression (BoW and TF-IDF):`\n",
    "- Hyperparameters to Tune:\n",
    "  - C: Inverse regularization strength (try different values, e.g., [0.01, 0.1, 1, 10, 100])\n",
    "  - penalty: Regularization type (e.g., ['l1', 'l2'])\n",
    "  - solver: Optimization algorithm (e.g., ['liblinear', 'saga'])\n",
    "  - max_iter: Maximum Iteration (e.g., [100, 200, 300])\n",
    "---\n",
    "`XGBoost (BoW and TF-IDF):`\n",
    "- Hyperparameters to Tune:\n",
    "  - n_estimators: Number of boosting rounds (try different values, e.g., [50, 100, 150, 200])\n",
    "  - max_depth: Maximum depth of a tree (try different values, e.g., [3, 5, 7])\n",
    "  - learning_rate: Step size shrinkage (e.g., [0.01, 0.1, 0.2])\n",
    "  - subsample: Fraction of samples used for training (e.g., [0.6, 0.8, 1.0])\n",
    "  - colsample_bytree: Fraction of features used for each tree (e.g., [0.6, 0.8, 1.0])\n",
    "---\n",
    "The hyperparameter tuning numbers were selected based on common practices for Logistic Regression and XGBoost, serving as standard starting points for balancing complexity, regularization, and learning behavior. While these values are widely used, they are customizable for different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df00ca5-c25e-4819-959e-714da94d44d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce2ba143-341f-432d-b453-e042cd083cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Relevant libraries\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ae1c87da-fb88-44a0-834e-eb443306dcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Logistic Regression (BoW) after Hyperparameter Tuning:\n",
      "Classification Report (BoW):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.50      0.51        30\n",
      "           1       0.96      0.97      0.96       409\n",
      "\n",
      "    accuracy                           0.93       439\n",
      "   macro avg       0.74      0.73      0.74       439\n",
      "weighted avg       0.93      0.93      0.93       439\n",
      "\n",
      "Evaluation for Logistic Regression (TF-IDF) after Hyperparameter Tuning:\n",
      "Classification Report (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.43      0.48        30\n",
      "           1       0.96      0.97      0.97       409\n",
      "\n",
      "    accuracy                           0.94       439\n",
      "   macro avg       0.75      0.70      0.72       439\n",
      "weighted avg       0.93      0.94      0.93       439\n",
      "\n",
      "Evaluation for XGBoost (BoW) after Hyperparameter Tuning:\n",
      "Classification Report (BoW):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.80      0.37        30\n",
      "           1       0.98      0.82      0.89       409\n",
      "\n",
      "    accuracy                           0.82       439\n",
      "   macro avg       0.61      0.81      0.63       439\n",
      "weighted avg       0.93      0.82      0.86       439\n",
      "\n",
      "Evaluation for XGBoost (TF-IDF)after Hyperparameter Tuning:\n",
      "Classification Report (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.83      0.39        30\n",
      "           1       0.99      0.82      0.90       409\n",
      "\n",
      "    accuracy                           0.82       439\n",
      "   macro avg       0.62      0.83      0.65       439\n",
      "weighted avg       0.94      0.82      0.86       439\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log Reg (BoW)</td>\n",
       "      <td>93.39%</td>\n",
       "      <td>93.34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Log Reg (TF-IDF)</td>\n",
       "      <td>93.62%</td>\n",
       "      <td>93.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB (BoW)</td>\n",
       "      <td>81.55%</td>\n",
       "      <td>85.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB (TF-IDF)</td>\n",
       "      <td>82.46%</td>\n",
       "      <td>86.30%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Accuracy F1 Score\n",
       "0     Log Reg (BoW)   93.39%   93.34%\n",
       "1  Log Reg (TF-IDF)   93.62%   93.29%\n",
       "2         XGB (BoW)   81.55%   85.63%\n",
       "3      XGB (TF-IDF)   82.46%   86.30%"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter grids\n",
    "# Define simplified parameter grids to reduce the number of combinations and speed up GridSearchCV\n",
    "log_reg_params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength for Logistic Regression; smaller values represent stronger regularization\n",
    "    'penalty': ['l1', 'l2'],  # Regularization types, 'l1' is Lasso (sparse solutions), 'l2' is Ridge (more regularized solutions)\n",
    "    'solver': ['liblinear', 'saga'],  # Optimization solvers; 'liblinear' for small datasets, 'saga' for larger, more complex problems\n",
    "    'max_iter': [100, 200, 300]  # Maximum number of iterations for the solver to converge; higher values ensure convergence for complex models\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100],  # Number of trees (boosting rounds) in XGBoost                              \n",
    "    'max_depth': [3, 5],  # Maximum depth of trees to control complexity and prevent overfitting                           \n",
    "    'learning_rate': [0.1],  # Step size shrinkage to make the boosting process more conservative\n",
    "    'subsample': [0.8],  # Fraction of samples used for training each tree to reduce overfitting  \n",
    "    'colsample_bytree': [0.8]  # Fraction of features used for building each tree to increase diversity among trees\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "log_reg_bow = LogisticRegression(class_weight = 'balanced')\n",
    "log_reg_tfidf = LogisticRegression(class_weight = 'balanced')\n",
    "xgb_bow = xgb.XGBClassifier(scale_pos_weight = scale_pos_weight)\n",
    "xgb_tfidf = xgb.XGBClassifier(scale_pos_weight = scale_pos_weight)\n",
    "\n",
    "#log_bow = LogisticRegression(class_weight='balanced')\n",
    "#log_tfidf = LogisticRegression(class_weight='balanced')\n",
    "#xgb_bow = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight)\n",
    "#xgb_tfidf = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "# Use 4-fold cross-validation (cv = 4) instead of 5-fold to reduce the computational cost and time\n",
    "# GridSearchCV for Logistic Regression (BoW)\n",
    "grid_log_reg_bow = GridSearchCV(log_bow, log_reg_params, scoring='f1_weighted', cv = 5)  # Perform hyperparameter tuning on Logistic Regression using GridSearchCV for BoW features with F1-weighted scoring and 4-fold CV\n",
    "grid_log_reg_bow.fit(X_train_bow, y_train)  # Fit the model on the BoW training data and labels\n",
    "\n",
    "# GridSearchCV for Logistic Regression (TF-IDF)\n",
    "grid_log_reg_tfidf = GridSearchCV(log_tfidf, log_reg_params, scoring='f1_weighted', cv = 5)  # Perform hyperparameter tuning on Logistic Regression using GridSearchCV for TF-IDF features\n",
    "grid_log_reg_tfidf.fit(X_train_tfidf, y_train)  # Fit the model on the TF-IDF training data and labels\n",
    "\n",
    "# GridSearchCV for XGBoost (BoW)\n",
    "grid_xgb_bow = GridSearchCV(xgb_bow, xgb_params, scoring='f1_weighted', cv = 5)  # Perform hyperparameter tuning on XGBoost using BoW features\n",
    "grid_xgb_bow.fit(X_train_bow, y_train)  # Fit the XGBoost model on the BoW training data\n",
    "\n",
    "# GridSearchCV for XGBoost (TF-IDF)\n",
    "grid_xgb_tfidf = GridSearchCV(xgb_tfidf, xgb_params, scoring='f1_weighted', cv = 5)  # Perform hyperparameter tuning on XGBoost using TF-IDF features\n",
    "grid_xgb_tfidf.fit(X_train_tfidf, y_train)  # Fit the XGBoost model on the TF-IDF training data\n",
    "\n",
    "# Get the best models from the grid search\n",
    "best_log_reg_bow = grid_log_reg_bow.best_estimator_  # Get the best-tuned Logistic Regression model for BoW\n",
    "best_log_reg_tfidf = grid_log_reg_tfidf.best_estimator_  # Get the best-tuned Logistic Regression model for TF-IDF\n",
    "best_xgb_bow = grid_xgb_bow.best_estimator_  # Get the best-tuned XGBoost model for BoW\n",
    "best_xgb_tfidf = grid_xgb_tfidf.best_estimator_  # Get the best-tuned XGBoost model for TF-IDF\n",
    "\n",
    "# Evaluate on the test set\n",
    "log_reg_bow_pred = best_log_reg_bow.predict(X_test_bow)  # Predict using the best Logistic Regression (BoW) model\n",
    "log_reg_tfidf_pred = best_log_reg_tfidf.predict(X_test_tfidf)  # Predict using the best Logistic Regression (TF-IDF) model\n",
    "xgb_bow_pred = best_xgb_bow.predict(X_test_bow)  # Predict using the best XGBoost (BoW) model\n",
    "xgb_tfidf_pred = best_xgb_tfidf.predict(X_test_tfidf)  # Predict using the best XGBoost (TF-IDF) model\n",
    "\n",
    "\n",
    "# Performance metrics for each model\n",
    "# Logistic Regression (BoW) Model\n",
    "print(\"Evaluation for Logistic Regression (BoW) after Hyperparameter Tuning:\")\n",
    "print(\"Classification Report (BoW):\")  # Display classification report for Log Reg (BoW) predictions\n",
    "print(classification_report(y_test, log_reg_bow_pred))  # Print precision, recall, F1 score for each class\n",
    "log_reg_bow_accuracy = (accuracy_score(y_test, log_reg_bow_pred)) * 100  # Calculate accuracy for Logistic Regression (BoW)\n",
    "log_reg_bow_f1 = (f1_score(y_test, log_reg_bow_pred, average='weighted')) * 100  # Calculate weighted F1 score for Logistic Regression (BoW)\n",
    "\n",
    "# Logistic Regression (TF-IDF) Model\n",
    "print(\"Evaluation for Logistic Regression (TF-IDF) after Hyperparameter Tuning:\")\n",
    "print(\"Classification Report (TF-IDF):\")  # Display classification report for Log Reg (TF-IDF) predictions\n",
    "print(classification_report(y_test, log_reg_tfidf_pred))  # Print precision, recall, F1 score for each class\n",
    "log_reg_tfidf_accuracy = (accuracy_score(y_test, log_reg_tfidf_pred)) * 100  # Calculate accuracy for Logistic Regression (TF-IDF)\n",
    "log_reg_tfidf_f1 = (f1_score(y_test, log_reg_tfidf_pred, average='weighted')) * 100  # Calculate weighted F1 score for Logistic Regression (TF-IDF)\n",
    "\n",
    "# XGBoost (BoW) Model\n",
    "print(\"Evaluation for XGBoost (BoW) after Hyperparameter Tuning:\")\n",
    "print(\"Classification Report (BoW):\")  # Display classification report for XGB (BoW) predictions\n",
    "print(classification_report(y_test, xgb_bow_pred))  # Print precision, recall, F1 score for each class\n",
    "xgb_bow_accuracy = (accuracy_score(y_test, xgb_bow_pred)) * 100  # Calculate accuracy for XGBoost (BoW)\n",
    "xgb_bow_f1 = (f1_score(y_test, xgb_bow_pred, average='weighted')) * 100  # Calculate weighted F1 score for XGBoost (BoW)\n",
    "\n",
    "# XGBoost (TF-IDF) Model\n",
    "print(\"Evaluation for XGBoost (TF-IDF)after Hyperparameter Tuning:\")\n",
    "print(\"Classification Report (TF-IDF):\")  # Display classification report for XGB (TF-IDF) predictions\n",
    "print(classification_report(y_test, xgb_tfidf_pred))  # Print precision, recall, F1 score for each class\n",
    "xgb_tfidf_accuracy = (accuracy_score(y_test, xgb_tfidf_pred)) * 100  # Calculate accuracy for XGBoost (TF-IDF)\n",
    "xgb_tfidf_f1 = (f1_score(y_test, xgb_tfidf_pred, average='weighted')) * 100  # Calculate weighted F1 score for XGBoost (TF-IDF)\n",
    "\n",
    "# Create a DataFrame to consolidate the evaluation metrics (accuracy and F1 score).\n",
    "# Create a dictionary with the model names and their corresponding accuracy and F1 scores\n",
    "evaluation_metrics2 = {\n",
    "    'Model': ['Log Reg (BoW)', 'Log Reg (TF-IDF)', 'XGB (BoW)', 'XGB (TF-IDF)'],  # Model names\n",
    "    'Accuracy': [log_reg_bow_accuracy, log_reg_tfidf_accuracy, xgb_bow_accuracy, xgb_tfidf_accuracy],  # Corresponding accuracies\n",
    "    'F1 Score': [log_reg_bow_f1, log_reg_tfidf_f1, xgb_bow_f1, xgb_tfidf_f1]  # Corresponding F1 scores\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "evaluation_data2 = pd.DataFrame(evaluation_metrics2)  # Create a DataFrame for evaluation metrics\n",
    "\n",
    "# Define a function to format the numbers as percentages\n",
    "def format_percentage(value):\n",
    "    return f'{value:.2f}%'\n",
    "\n",
    "# Use apply with the custom function for both columns\n",
    "evaluation_data2['Accuracy'] = evaluation_data2['Accuracy'].apply(format_percentage)  # Format accuracy as percentage\n",
    "evaluation_data2['F1 Score'] = evaluation_data2['F1 Score'].apply(format_percentage)  # Format F1 score as percentage\n",
    "\n",
    "# Display the evaluation metrics DataFrame\n",
    "evaluation_data2  # Show the DataFrame with formatted percentages for accuracy and F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f6886b-62e3-480c-a2f5-6258c1bcafb8",
   "metadata": {},
   "source": [
    "#### Model Evaluation Insights After Hyperparameter Tuning\n",
    "---\n",
    "`1. Logistic Regression (BoW):`\n",
    "- F1-score: 51% (negatives), 96% (positives)\n",
    "- Accuracy: 93%\n",
    "- **Insight: Slight improvement in negative sentiment detection but remains stable in positive classification.**\n",
    "---\n",
    "`2. Logistic Regression (TF-IDF):`\n",
    "- F1-score: 48% (negatives), 97% (positives)\n",
    "- Accuracy: 94%\n",
    "- **Insight: Recall for negatives decreases (43%), indicating reduced effectiveness in capturing negative sentiment.**\n",
    "---\n",
    "`3. XGBoost (BoW):`\n",
    "- F1-score: 37% (negatives), 89% (positives)\n",
    "- Accuracy: 82%\n",
    "- **Insight: Slight improvement in recall for negatives (80%), but still lacks reliability for balanced tasks.**\n",
    "---\n",
    "`4. XGBoost (TF-IDF):`\n",
    "- F1-score: 39% (negatives), 90% (positives)\n",
    "- Accuracy: 82%\n",
    "- **Insight: Shows slight improvements for negative sentiment detection but remains imbalanced.**\n",
    "---\n",
    "\n",
    "**Best Model Decision**\n",
    "- Based on the insights from the evaluations:\n",
    "\n",
    "  - 1. Logistic Regression (BoW) is the best-performing model with the highest accuracy (93.39%) and the best balance in F1 score (93.34%). Its reliability in classifying both positive and negative sentiments, combined with high recall for positive sentiment, makes it a robust choice.\n",
    "\n",
    "  - 2. Logistic Regression (TF-IDF) also performs well but shows a slight decrease in negative sentiment detection.\n",
    "\n",
    "  - 3. XGBoost models, despite improvements, still lag in overall performance compared to Logistic Regression, particularly in handling negative sentiment.\n",
    "\n",
    "**Conclusion**\n",
    "- **Deploy Logistic Regression (BoW) as the best model for sentiment classification due to its strong performance across all metrics and its balanced handling of both sentiment classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b7c7c-bb58-4db3-a676-b063af8736d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08a193-6c81-47a0-aea3-e0399911fe6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90670517-4133-44eb-b47c-d721be28c750",
   "metadata": {},
   "source": [
    "# 6. Model Deployment\n",
    "\n",
    "#### 1. Flask Deployment Steps\n",
    "   - Create a project folder.\n",
    "   - Set up a virtual environment: conda create -p alpha_team_sentiment_analyzer_model_deploy_venv python==3.9 scikit-learn==1.3.0 -y \n",
    "   - Activate the virtual environment: conda activate alpha_team_sentiment_analyzer_model_deploy_venv\n",
    "   - Install required packages: pip install flask scikit-learn pandas numpy\n",
    "   - Save your trained model and vectorizer using pickle.\n",
    "   - Create a app.py file with Flask app code.\n",
    "   - Define the prediction route and load the model/vectorizer in app.py.\n",
    "   - Run the Flask app:python app.py\n",
    "   - Test the API using cURL or Postman.\n",
    "---\n",
    "#### 2. Streamlit Deployment Steps\n",
    "   - Create a project folder.\n",
    "   - Set up a virtual environment (same as with flask).\n",
    "   - Activate the virtual environment.(same as with flask).\n",
    "   - Install required packages: pip install streamlit scikit-learn pandas numpy\n",
    "   - Save your trained model and vectorizer using pickle.\n",
    "   - Create a streamlit_app.py file with Streamlit app code.\n",
    "   - Load the model/vectorizer in streamlit_app.py.\n",
    "   - Define the Streamlit app layout and prediction logic.\n",
    "   - Run the Streamlit app: streamlit run streamlit_app.py\n",
    "   - Test the app in a web browser.\n",
    "---\n",
    "#### 3. Integrated Guide for Deploying Machine Learning Models with Flask and Streamlit Steps\n",
    "   - Create a project folder.\n",
    "   - Set up a virtual environment: conda create -p alpha_team_sentiment_analyzer_model_deploy_venv python==3.9 scikit-learn==1.3.0 -y\n",
    "   - Activate the virtual environment: conda activate alpha_team_sentiment_analyzer_model_deploy_venv\n",
    "   - Install required packages: pip install flask streamlit scikit-learn pandas numpy\n",
    "   - Save your trained model and vectorizer using pickle.\n",
    "   - Create app.py for Flask deployment.\n",
    "   - Load model and vectorizer.\n",
    "   - Define the prediction route.\n",
    "   - Create streamlit_app.py for Streamlit deployment.\n",
    "   - Load model and vectorizer.\n",
    "   - Define the app layout and prediction logic.\n",
    "   - Run the Flask app: python app.py\n",
    "   - Run the Streamlit app: streamlit run streamlit_app.py\n",
    "   - Test both applications using cURL/Postman for Flask and a web browser for Streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa4a95-93f0-4e21-a2a8-fae988d4e93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb41621f-432f-4fa9-995d-0ed3a58b3bb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save Trained Model and Vectorizer using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aceaa9b2-220c-4aab-8e8b-dfdc6d6ccede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "import pickle\n",
    "\n",
    "# Saving the Logistic Regression bow Model (after Hyperparameter tuning)\n",
    "with open('log_reg_bow_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(grid_log_reg_bow, model_file)  # Save the trained model\n",
    "\n",
    "# Saving the Vectorizer for Bag of Words from the feature engin\n",
    "with open('vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(bow_vectorizer, vectorizer_file)  # Save the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194890c-4d13-4ee4-926f-defab3fb3ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092d968-eedd-4b23-9754-266d4dc3f6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91cff9-15d2-4b0b-95f6-73af5abc9ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0b5d0-346a-4dfd-9f12-3648495394fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3179f-f527-4bb2-a932-7f3a6bc5f1d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7785f-ccf7-4907-8ef3-9bbeb578c24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e420cb-cd1c-4370-b9df-0fdc9292c097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
